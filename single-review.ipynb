{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great CD</td>\n",
       "      <td>My lovely Pat has one of the GREAT voices of ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "      <td>Despite the fact that I have only played a sm...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batteries died within a year ...</td>\n",
       "      <td>I bought this charger in Jul 2003 and it work...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works fine, but Maha Energy is better</td>\n",
       "      <td>Check out Maha Energy's website. Their Powere...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great for the non-audiophile</td>\n",
       "      <td>Reviewed quite a bit of the combo players and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                           Great CD   \n",
       "1  One of the best game music soundtracks - for a...   \n",
       "2                   Batteries died within a year ...   \n",
       "3              works fine, but Maha Energy is better   \n",
       "4                       Great for the non-audiophile   \n",
       "\n",
       "                                              review  label  \n",
       "0   My lovely Pat has one of the GREAT voices of ...      2  \n",
       "1   Despite the fact that I have only played a sm...      2  \n",
       "2   I bought this charger in Jul 2003 and it work...      1  \n",
       "3   Check out Maha Energy's website. Their Powere...      2  \n",
       "4   Reviewed quite a bit of the combo players and...      2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400000 entries, 0 to 399999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   title   399912 non-null  object\n",
      " 1   review  400000 non-null  object\n",
      " 2   label   400000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800000, 3)\n",
      "(1800000, 3)\n"
     ]
    }
   ],
   "source": [
    "label1DF = train_df[train_df['label']== 1]\n",
    "label2DF = train_df[train_df['label']==2]\n",
    "\n",
    "print(label1DF.shape)\n",
    "print(label2DF.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a \"lean\" on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please don't waste your money. I too, believe that the good reviews must have been written by the author's relatives. I will not put much faith in the reviews from now on!\n",
      "\n",
      "['I', 'feel', 'I', 'have', 'to', 'write', 'to', 'keep', 'others', 'from', 'wasting', 'their', 'money', '.', 'This', 'book', 'seems', 'to', 'ha']\n"
     ]
    }
   ],
   "source": [
    "label1_tokens = list()\n",
    "\n",
    "print(label1DF.iloc[3]['review'])\n",
    "text = '''I feel I have to write to keep others from wasting their money. This book seems to ha '''\n",
    "token = word_tokenize(text)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Buyer beware</td>\n",
       "      <td>This is a self-published book, and if you wan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Worst!</td>\n",
       "      <td>A complete waste of time. Typographical error...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Oh please</td>\n",
       "      <td>I guess you have to be a romance novel lover ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Awful beyond belief!</td>\n",
       "      <td>I feel I have to write to keep others from wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Don't try to fool us with fake reviews.</td>\n",
       "      <td>It's glaringly obvious that all of the glowin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "6                              Buyer beware   \n",
       "10                               The Worst!   \n",
       "13                                Oh please   \n",
       "14                     Awful beyond belief!   \n",
       "15  Don't try to fool us with fake reviews.   \n",
       "\n",
       "                                               review  label  \n",
       "6    This is a self-published book, and if you wan...      1  \n",
       "10   A complete waste of time. Typographical error...      1  \n",
       "13   I guess you have to be a romance novel lover ...      1  \n",
       "14   I feel I have to write to keep others from wa...      1  \n",
       "15   It's glaringly obvious that all of the glowin...      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label1DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/pgc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "label1_tokens = list()\n",
    "\n",
    "for i in range(label1DF[\"review\"].shape[0]):\n",
    "    #lowercase letters \n",
    "    tokens = word_tokenize(label1DF.iloc[i][\"review\"].lower())\n",
    "    label1_tokens.extend(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2_tokens = list()\n",
    "\n",
    "for i in range(label2DF['review'].shape[0]):\n",
    "    tokens = word_tokenize(label2DF.iloc[i][\"review\"].lower())\n",
    "    label2_tokens.extend(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'movie', 'was', 'terrible', '!', '``', 'warning', 'spoliers', 'may', 'be', 'possible', '!', '``', 'well', 'it', 'starts', 'out', 'with', 'davey', ',', 'a', 'drunk', 'who', 'is', 'crude', 'and', 'mean', '.', 'then', 'when', 'he', 'gets', 'into', 'trouble', 'he', \"'s\", 'doomed', 'to', 'community', 'service', 'with', 'the', 'town', 'migiet', 'whitney', ',', '(', 'no', 'offence', 'to', 'little', 'people', 'out', 'there', ',', 'that', 'it', 'not', 'my', 'intention', 'to', 'offend', 'anyone', ')', '.', 'whitney', 'sounds', 'like', 'woody', 'allen', 'on', 'crack', ',', 'and', 'his', 'fernal', 'twin', 'sister', 'elenaor', 'is', \"n't\", 'any', 'better.well', 'davey', 'does', 'all', 'he', 'can', 'to', 'offend', 'whitney', '.', 'that', 'is', 'until', 'his', 'place', 'burns', 'up', '!', 'so', 'he', 'moves', 'in', 'with', 'whitney', 'and', 'his', 'sister', ',', 'and', 'they', 'set', 'some', 'ground', 'rules', '.', 'then', 'as', 'the', 'movie', 'goes', 'on', ',', 'they', 'make', 'a', 'big', 'deal', 'about', 'davey', 'having', 'little', 'emotion', ',', 'and', 'when', 'he', 'cries', 'it', \"'s\", 'all', 'the', 'sudden', 'a', 'big', 'deal', '!', 'and', 'for', 'some', 'reason', 'the', 'deer', 'in', 'the', 'woods', 'talk', ',', 'and', 'help', 'whitney', 'out', '.', 'what', 'or', 'who', 'is', 'whitney', 'supposted', 'to', 'be', 'santa', 'claus', '?', 'i', 'hate', 'the', 'music', 'in', 'it', ',', 'the', 'voices', 'are', 'annoying', ',', 'and', 'the', 'characters', 'are', 'mostly', 'unlikable', '!', 'so', 'warning', 'to', 'parents', ',', 'keep', 'your', 'children', 'locked', 'up', 'from', 'this', 'totally', 'bad', 'movie', '!']\n",
      "{'will', 'not', \"that'll\", 'from', 'their', 'own', 'in', 'too', 's', 'ain', \"shouldn't\", 'm', 'needn', 'those', 'do', \"don't\", 'same', 'aren', 'why', 'for', 'once', \"hasn't\", 'with', \"she's\", 'while', 'yourself', 'shan', 'mustn', 'himself', \"shan't\", 'theirs', 'i', 'it', 'which', 'wouldn', 'up', 'most', 'than', 'what', 'doesn', 'didn', 'wasn', 'by', 'does', 'herself', 'out', 'being', 'our', 'through', 'itself', 'to', 'myself', 'under', 've', 'been', 'the', 'of', \"haven't\", 'is', 'such', 'are', 'she', 'couldn', 'all', 'these', 'between', 'at', \"should've\", \"it's\", 'hadn', \"mightn't\", \"wasn't\", \"mustn't\", 'his', 'hasn', 'against', 'very', \"you're\", 'your', 'if', 'so', 'have', 'can', 'yours', 'more', 'had', 'haven', 'they', 'my', 'he', 'off', 'on', 'no', 'then', 'has', 'when', 'd', 'each', 'weren', 'over', 'further', 'll', 'should', 'and', 'some', \"didn't\", 'ourselves', 'did', 't', 'this', 'other', 'mightn', 'its', 'isn', \"doesn't\", 'again', 'a', \"aren't\", 'because', \"hadn't\", 'you', 'below', \"isn't\", 'ours', 'we', 'that', 'until', \"weren't\", 'now', \"needn't\", 'where', 'was', 'me', 'don', 'an', 'be', 'about', \"wouldn't\", 'after', \"won't\", 'here', 'them', 'just', 're', 'doing', 'yourselves', 'during', 'who', \"you've\", 'above', 'were', 'there', 'into', 'as', 'nor', 'but', 'o', 'her', 'how', 'few', 'him', 'both', 'ma', \"you'll\", 'any', 'won', 'am', 'having', \"couldn't\", 'whom', 'themselves', 'before', 'or', 'only', \"you'd\", 'y', 'shouldn', 'hers', 'down'}\n",
      "[('movie', 'terrible'), ('terrible', 'warning'), ('warning', 'spoliers'), ('spoliers', 'may'), ('may', 'possible'), ('possible', 'well'), ('well', 'starts'), ('starts', 'davey'), ('davey', 'drunk'), ('drunk', 'crude'), ('crude', 'mean'), ('mean', 'gets'), ('gets', 'trouble'), ('trouble', 'doomed'), ('doomed', 'community'), ('community', 'service'), ('service', 'town'), ('town', 'migiet'), ('migiet', 'whitney'), ('whitney', 'offence'), ('offence', 'little'), ('little', 'people'), ('people', 'intention'), ('intention', 'offend'), ('offend', 'anyone'), ('anyone', 'whitney'), ('whitney', 'sounds'), ('sounds', 'like'), ('like', 'woody'), ('woody', 'allen'), ('allen', 'crack'), ('crack', 'fernal'), ('fernal', 'twin'), ('twin', 'sister'), ('sister', 'elenaor'), ('elenaor', 'davey'), ('davey', 'offend'), ('offend', 'whitney'), ('whitney', 'place'), ('place', 'burns'), ('burns', 'moves'), ('moves', 'whitney'), ('whitney', 'sister'), ('sister', 'set'), ('set', 'ground'), ('ground', 'rules'), ('rules', 'movie'), ('movie', 'goes'), ('goes', 'make'), ('make', 'big'), ('big', 'deal'), ('deal', 'davey'), ('davey', 'little'), ('little', 'emotion'), ('emotion', 'cries'), ('cries', 'sudden'), ('sudden', 'big'), ('big', 'deal'), ('deal', 'reason'), ('reason', 'deer'), ('deer', 'woods'), ('woods', 'talk'), ('talk', 'help'), ('help', 'whitney'), ('whitney', 'whitney'), ('whitney', 'supposted'), ('supposted', 'santa'), ('santa', 'claus'), ('claus', 'hate'), ('hate', 'music'), ('music', 'voices'), ('voices', 'annoying'), ('annoying', 'characters'), ('characters', 'mostly'), ('mostly', 'unlikable'), ('unlikable', 'warning'), ('warning', 'parents'), ('parents', 'keep'), ('keep', 'children'), ('children', 'locked'), ('locked', 'totally'), ('totally', 'bad'), ('bad', 'movie')]\n",
      "[('movie', 'terrible', 'warning'), ('terrible', 'warning', 'spoliers'), ('warning', 'spoliers', 'may'), ('spoliers', 'may', 'possible'), ('may', 'possible', 'well'), ('possible', 'well', 'starts'), ('well', 'starts', 'davey'), ('starts', 'davey', 'drunk'), ('davey', 'drunk', 'crude'), ('drunk', 'crude', 'mean'), ('crude', 'mean', 'gets'), ('mean', 'gets', 'trouble'), ('gets', 'trouble', 'doomed'), ('trouble', 'doomed', 'community'), ('doomed', 'community', 'service'), ('community', 'service', 'town'), ('service', 'town', 'migiet'), ('town', 'migiet', 'whitney'), ('migiet', 'whitney', 'offence'), ('whitney', 'offence', 'little'), ('offence', 'little', 'people'), ('little', 'people', 'intention'), ('people', 'intention', 'offend'), ('intention', 'offend', 'anyone'), ('offend', 'anyone', 'whitney'), ('anyone', 'whitney', 'sounds'), ('whitney', 'sounds', 'like'), ('sounds', 'like', 'woody'), ('like', 'woody', 'allen'), ('woody', 'allen', 'crack'), ('allen', 'crack', 'fernal'), ('crack', 'fernal', 'twin'), ('fernal', 'twin', 'sister'), ('twin', 'sister', 'elenaor'), ('sister', 'elenaor', 'davey'), ('elenaor', 'davey', 'offend'), ('davey', 'offend', 'whitney'), ('offend', 'whitney', 'place'), ('whitney', 'place', 'burns'), ('place', 'burns', 'moves'), ('burns', 'moves', 'whitney'), ('moves', 'whitney', 'sister'), ('whitney', 'sister', 'set'), ('sister', 'set', 'ground'), ('set', 'ground', 'rules'), ('ground', 'rules', 'movie'), ('rules', 'movie', 'goes'), ('movie', 'goes', 'make'), ('goes', 'make', 'big'), ('make', 'big', 'deal'), ('big', 'deal', 'davey'), ('deal', 'davey', 'little'), ('davey', 'little', 'emotion'), ('little', 'emotion', 'cries'), ('emotion', 'cries', 'sudden'), ('cries', 'sudden', 'big'), ('sudden', 'big', 'deal'), ('big', 'deal', 'reason'), ('deal', 'reason', 'deer'), ('reason', 'deer', 'woods'), ('deer', 'woods', 'talk'), ('woods', 'talk', 'help'), ('talk', 'help', 'whitney'), ('help', 'whitney', 'whitney'), ('whitney', 'whitney', 'supposted'), ('whitney', 'supposted', 'santa'), ('supposted', 'santa', 'claus'), ('santa', 'claus', 'hate'), ('claus', 'hate', 'music'), ('hate', 'music', 'voices'), ('music', 'voices', 'annoying'), ('voices', 'annoying', 'characters'), ('annoying', 'characters', 'mostly'), ('characters', 'mostly', 'unlikable'), ('mostly', 'unlikable', 'warning'), ('unlikable', 'warning', 'parents'), ('warning', 'parents', 'keep'), ('parents', 'keep', 'children'), ('keep', 'children', 'locked'), ('children', 'locked', 'totally'), ('locked', 'totally', 'bad'), ('totally', 'bad', 'movie')]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "location = math.ceil(random.random()*1000)\n",
    "\n",
    "tokens = word_tokenize(label1DF.iloc[location]['review'].lower())\n",
    "print(tokens)\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "words = [w for w in tokens if w.isalnum() and w not in stop_words]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = pos_tag(words)\n",
    "named_entities = ne_chunk(pos_tag(words))\n",
    "entities = [(chunk.label(), ' '.join(c[0] for c in chunk.leaves()))\n",
    "                for chunk in named_entities if hasattr(chunk, 'label')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('movie', 'terrible'), ('terrible', 'warning'), ('warning', 'spoliers'), ('spoliers', 'may'), ('may', 'possible'), ('possible', 'well'), ('well', 'starts'), ('starts', 'davey'), ('davey', 'drunk'), ('drunk', 'crude'), ('crude', 'mean'), ('mean', 'gets'), ('gets', 'trouble'), ('trouble', 'doomed'), ('doomed', 'community'), ('community', 'service'), ('service', 'town'), ('town', 'migiet'), ('migiet', 'whitney'), ('whitney', 'offence'), ('offence', 'little'), ('little', 'people'), ('people', 'intention'), ('intention', 'offend'), ('offend', 'anyone'), ('anyone', 'whitney'), ('whitney', 'sounds'), ('sounds', 'like'), ('like', 'woody'), ('woody', 'allen'), ('allen', 'crack'), ('crack', 'fernal'), ('fernal', 'twin'), ('twin', 'sister'), ('sister', 'elenaor'), ('elenaor', 'davey'), ('davey', 'offend'), ('offend', 'whitney'), ('whitney', 'place'), ('place', 'burns'), ('burns', 'moves'), ('moves', 'whitney'), ('whitney', 'sister'), ('sister', 'set'), ('set', 'ground'), ('ground', 'rules'), ('rules', 'movie'), ('movie', 'goes'), ('goes', 'make'), ('make', 'big'), ('big', 'deal'), ('deal', 'davey'), ('davey', 'little'), ('little', 'emotion'), ('emotion', 'cries'), ('cries', 'sudden'), ('sudden', 'big'), ('big', 'deal'), ('deal', 'reason'), ('reason', 'deer'), ('deer', 'woods'), ('woods', 'talk'), ('talk', 'help'), ('help', 'whitney'), ('whitney', 'whitney'), ('whitney', 'supposted'), ('supposted', 'santa'), ('santa', 'claus'), ('claus', 'hate'), ('hate', 'music'), ('music', 'voices'), ('voices', 'annoying'), ('annoying', 'characters'), ('characters', 'mostly'), ('mostly', 'unlikable'), ('unlikable', 'warning'), ('warning', 'parents'), ('parents', 'keep'), ('keep', 'children'), ('children', 'locked'), ('locked', 'totally'), ('totally', 'bad'), ('bad', 'movie')]\n",
      "[('movie', 'terrible', 'warning'), ('terrible', 'warning', 'spoliers'), ('warning', 'spoliers', 'may'), ('spoliers', 'may', 'possible'), ('may', 'possible', 'well'), ('possible', 'well', 'starts'), ('well', 'starts', 'davey'), ('starts', 'davey', 'drunk'), ('davey', 'drunk', 'crude'), ('drunk', 'crude', 'mean'), ('crude', 'mean', 'gets'), ('mean', 'gets', 'trouble'), ('gets', 'trouble', 'doomed'), ('trouble', 'doomed', 'community'), ('doomed', 'community', 'service'), ('community', 'service', 'town'), ('service', 'town', 'migiet'), ('town', 'migiet', 'whitney'), ('migiet', 'whitney', 'offence'), ('whitney', 'offence', 'little'), ('offence', 'little', 'people'), ('little', 'people', 'intention'), ('people', 'intention', 'offend'), ('intention', 'offend', 'anyone'), ('offend', 'anyone', 'whitney'), ('anyone', 'whitney', 'sounds'), ('whitney', 'sounds', 'like'), ('sounds', 'like', 'woody'), ('like', 'woody', 'allen'), ('woody', 'allen', 'crack'), ('allen', 'crack', 'fernal'), ('crack', 'fernal', 'twin'), ('fernal', 'twin', 'sister'), ('twin', 'sister', 'elenaor'), ('sister', 'elenaor', 'davey'), ('elenaor', 'davey', 'offend'), ('davey', 'offend', 'whitney'), ('offend', 'whitney', 'place'), ('whitney', 'place', 'burns'), ('place', 'burns', 'moves'), ('burns', 'moves', 'whitney'), ('moves', 'whitney', 'sister'), ('whitney', 'sister', 'set'), ('sister', 'set', 'ground'), ('set', 'ground', 'rules'), ('ground', 'rules', 'movie'), ('rules', 'movie', 'goes'), ('movie', 'goes', 'make'), ('goes', 'make', 'big'), ('make', 'big', 'deal'), ('big', 'deal', 'davey'), ('deal', 'davey', 'little'), ('davey', 'little', 'emotion'), ('little', 'emotion', 'cries'), ('emotion', 'cries', 'sudden'), ('cries', 'sudden', 'big'), ('sudden', 'big', 'deal'), ('big', 'deal', 'reason'), ('deal', 'reason', 'deer'), ('reason', 'deer', 'woods'), ('deer', 'woods', 'talk'), ('woods', 'talk', 'help'), ('talk', 'help', 'whitney'), ('help', 'whitney', 'whitney'), ('whitney', 'whitney', 'supposted'), ('whitney', 'supposted', 'santa'), ('supposted', 'santa', 'claus'), ('santa', 'claus', 'hate'), ('claus', 'hate', 'music'), ('hate', 'music', 'voices'), ('music', 'voices', 'annoying'), ('voices', 'annoying', 'characters'), ('annoying', 'characters', 'mostly'), ('characters', 'mostly', 'unlikable'), ('mostly', 'unlikable', 'warning'), ('unlikable', 'warning', 'parents'), ('warning', 'parents', 'keep'), ('parents', 'keep', 'children'), ('keep', 'children', 'locked'), ('children', 'locked', 'totally'), ('locked', 'totally', 'bad'), ('totally', 'bad', 'movie')]\n"
     ]
    }
   ],
   "source": [
    "#bigrams\n",
    "bigrams = list(ngrams(words, 2))\n",
    "trigrams = list(ngrams(words, 3))\n",
    "print(bigrams)\n",
    "print(trigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "someExtraWords =  {\"n't\",  \"'ll\", \"'ve\", \"'s\",\"'d\", \"'m\", \"''\", \"``\", \"'re\", \"^^\", \":\", \"_\", \"/\", \"+\", \"-\"}\n",
    "def removeStopWords(tokens):\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    \n",
    "    for word in someExtraWords:\n",
    "        stopWords.add(word)\n",
    "    for punctuation in string.punctuation:\n",
    "        stopWords.add(punctuation)\n",
    "    \n",
    "    return [token for token in tokens if token not in stopWords]\n",
    "\n",
    "\n",
    "\n",
    "label1_tokens = removeStopWords(label1_tokens)\n",
    "label2_tokens = removeStopWords(label2_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "label1_tokens = [wnl.lemmatize(token) for token in label1_tokens]\n",
    "label2_tokens = [wnl.lemmatize(token) for token in label2_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens_label1 = set(label1_tokens)\n",
    "unique_tokens_label2 = set(label2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words Positive Reviews:  1204551\n",
      "Unique words Neagtive Reviews:  1166479\n",
      "Total unique words:  2371030\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique words Positive Reviews: \", len(unique_tokens_label2))\n",
    "print(\"Unique words Neagtive Reviews: \", len(unique_tokens_label1))\n",
    "print(\"Total unique words: \", len(unique_tokens_label1) + len(unique_tokens_label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1_token_freq = FreqDist(label1_tokens)\n",
    "label2_token_freq = FreqDist(label2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 tokens in label 1 are (Negative Reviews): [('book', 1001077), ('one', 685655), ('would', 559128), ('like', 525171), ('get', 415297), ('time', 412043), ('good', 369559), ('movie', 340397), ('...', 319877), ('even', 308521), ('read', 283207), ('product', 282363), ('could', 273156), ('work', 271111), ('really', 266412), ('much', 263070), ('first', 247573), ('buy', 243728), ('make', 229552), ('money', 225501), ('bought', 217240), ('better', 216750), ('great', 200982), ('use', 198828), ('year', 193981), ('thing', 193883), ('back', 190419), ('well', 185199), ('way', 184149), ('bad', 181195), ('got', 173581), ('never', 173180), ('know', 172700), ('story', 170428), ('think', 169023), ('want', 167781), ('new', 166341), ('two', 165081), ('say', 162004), ('cd', 160746), ('review', 160726), ('also', 160273), ('go', 158332), ('many', 153492), ('made', 152667), ('character', 145959), ('people', 145818), ('see', 143213), ('little', 140831), ('game', 139913)]\n",
      "Top 50 tokens in label 2 are (Positive Reviews): [('book', 1038106), ('one', 649058), ('great', 588831), ('like', 480773), ('good', 459009), ('time', 362834), ('read', 358936), ('love', 356805), ('would', 334518), ('get', 322665), ('well', 302039), ('movie', 284300), ('really', 281329), ('work', 239876), ('album', 239643), ('cd', 236144), ('best', 234767), ('...', 234393), ('make', 233347), ('year', 230144), ('first', 228206), ('story', 224768), ('song', 221353), ('much', 216395), ('also', 214063), ('use', 186433), ('little', 180932), ('even', 179722), ('music', 176315), ('could', 172111), ('many', 171303), ('way', 169915), ('new', 164228), ('recommend', 163335), ('think', 163315), ('life', 160264), ('still', 157273), ('know', 154846), ('thing', 152951), ('better', 149031), ('easy', 148544), ('bought', 147133), ('buy', 146533), ('go', 145253), ('find', 144484), ('product', 143497), ('want', 142080), ('see', 140712), ('lot', 133107), ('day', 132530)]\n"
     ]
    }
   ],
   "source": [
    "top_k = 50\n",
    "print(f\"Top {top_k} tokens in label 1 are (Negative Reviews): {label1_token_freq.most_common(top_k)}\")\n",
    "print(f\"Top {top_k} tokens in label 2 are (Positive Reviews): {label2_token_freq.most_common(top_k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
